name: Build Push Deploy (AKS)

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  NAMESPACE: prodental
  ACR_LOGIN_SERVER: ${{ secrets.ACR_LOGIN_SERVER }}
  AKS_CLUSTER_NAME: ${{ secrets.AKS_CLUSTER_NAME }}
  AKS_RESOURCE_GROUP: ${{ secrets.AKS_RESOURCE_GROUP }}

jobs:
  build_push_deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      # ✅ Create one short tag for the whole workflow (consistent across steps)
      - name: Set image tags
        shell: bash
        run: |
          TAG="${GITHUB_SHA::7}"
          echo "TAG=$TAG" >> $GITHUB_ENV
          echo "BACKEND_TAG=$TAG" >> $GITHUB_ENV
          echo "FRONTEND_TAG=$TAG" >> $GITHUB_ENV

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4

      - name: Get AKS credentials
        shell: bash
        run: |
          az aks get-credentials \
            --resource-group "$AKS_RESOURCE_GROUP" \
            --name "$AKS_CLUSTER_NAME" \
            --overwrite-existing

      - name: ACR Login
        shell: bash
        run: |
          az acr login --name "${ACR_LOGIN_SERVER%%.*}"

      # ✅ Optional but recommended: Buildx for better caching & reliability
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Debug - list repo files
        shell: bash
        run: |
          pwd
          ls -la
          echo "---- backend ----"
          ls -la backend || true
          echo "---- backend/src ----"
          ls -la backend/src || true
          echo "---- backend/.dockerignore ----"
          cat backend/.dockerignore || true
          echo "---- root .dockerignore ----"
          cat .dockerignore || true
          echo "---- frontend ----"
          ls -la frontend || true
          echo "---- frontend/.dockerignore ----"
          cat frontend/.dockerignore || true

      # ✅ Backend build context fix (use ./backend as context)
      - name: Build & Push Backend Image
        uses: docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          platforms: linux/amd64
          pull: true
          no-cache: true
          tags: ${{ env.ACR_LOGIN_SERVER }}/prodental-backend:${{ env.BACKEND_TAG }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build & Push Frontend Image
        uses: docker/build-push-action@v6
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ env.ACR_LOGIN_SERVER }}/prodental-frontend:${{ env.FRONTEND_TAG }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # ✅ Avoid ConfigMap binaryData/data duplicate apply issues
      - name: Apply Kubernetes manifests (safe ConfigMap apply)
        shell: bash
        run: |
          # Namespace
          kubectl get ns "$NAMESPACE" >/dev/null 2>&1 || kubectl create ns "$NAMESPACE"

          # 1) Force-replace SQL ConfigMap (prevents binaryData/data duplicate key apply failure)
          kubectl -n "$NAMESPACE" delete configmap prodental-sql --ignore-not-found
          kubectl -n "$NAMESPACE" apply -f k8s/02-sql-configmap.yaml

          # 2) Apply the rest safely WITHOUT re-applying the same configmap again
          #    (Assumption: k8s/ folder contains multiple YAMLs including 02-sql-configmap.yaml)
          find k8s -type f \( -name "*.yml" -o -name "*.yaml" \) \
            ! -path "k8s/02-sql-configmap.yaml" \
            -print0 | xargs -0 -I {} kubectl -n "$NAMESPACE" apply -f {}

      # ✅ Extra diagnostics: show deployments if set-image fails later
      - name: Debug - list deployments in namespace
        shell: bash
        run: |
          kubectl -n "$NAMESPACE" get deploy -o wide || true

      # ✅ Auto-detect deployments and update images safely
      - name: Update images in AKS (auto-detect deployments)
        shell: bash
        run: |
          set -euo pipefail

          # Try common names first
          BACKEND_DEPLOY="backend"
          FRONTEND_DEPLOY="frontend"

          if ! kubectl -n "$NAMESPACE" get deploy "$BACKEND_DEPLOY" >/dev/null 2>&1; then
            BACKEND_DEPLOY="$(kubectl -n "$NAMESPACE" get deploy -o name | grep -i 'backend' | head -n 1 | sed 's|deployment.apps/||')"
          fi

          if ! kubectl -n "$NAMESPACE" get deploy "$FRONTEND_DEPLOY" >/dev/null 2>&1; then
            FRONTEND_DEPLOY="$(kubectl -n "$NAMESPACE" get deploy -o name | grep -i 'frontend' | head -n 1 | sed 's|deployment.apps/||')"
          fi

          echo "Detected backend deployment: ${BACKEND_DEPLOY:-NOT_FOUND}"
          echo "Detected frontend deployment: ${FRONTEND_DEPLOY:-NOT_FOUND}"

          if [ -z "${BACKEND_DEPLOY:-}" ] || [ -z "${FRONTEND_DEPLOY:-}" ]; then
            echo "ERROR: Could not detect backend/frontend deployments. Listing deployments:"
            kubectl -n "$NAMESPACE" get deploy -o wide
            exit 1
          fi

          # Save detected names for later steps (rollout)
          echo "BACKEND_DEPLOY=$BACKEND_DEPLOY" >> $GITHUB_ENV
          echo "FRONTEND_DEPLOY=$FRONTEND_DEPLOY" >> $GITHUB_ENV

          kubectl -n "$NAMESPACE" set image "deploy/$BACKEND_DEPLOY"  backend="$ACR_LOGIN_SERVER/prodental-backend:$BACKEND_TAG"
          kubectl -n "$NAMESPACE" set image "deploy/$FRONTEND_DEPLOY" frontend="$ACR_LOGIN_SERVER/prodental-frontend:$FRONTEND_TAG"

      - name: Wait for rollout
        shell: bash
        run: |
          kubectl -n "$NAMESPACE" rollout status "deploy/$BACKEND_DEPLOY"  --timeout=180s
          kubectl -n "$NAMESPACE" rollout status "deploy/$FRONTEND_DEPLOY" --timeout=180s
